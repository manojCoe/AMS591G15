% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bagging.R
\name{bagging}
\alias{bagging}
\title{Bagging Function}
\usage{
bagging(
  x,
  y,
  testData,
  model_type,
  responseVariable = NULL,
  R = 10,
  type = "default",
  lambda = NULL,
  alpha = NULL,
  ignoreWarnings = T,
  importance = NULL,
  nfolds = 10,
  kernel = "radial",
  cost = 1,
  degree = 3,
  coef0 = 0,
  gamma = NULL,
  epsilon = 0.1,
  k = 6
)
}
\arguments{
\item{x}{Training features as a data frame, matrix, or numeric vector.}

\item{y}{Training labels as a data frame, matrix, factor, or numeric vector.}

\item{testData}{Test data as a data frame or matrix.}

\item{model_type}{Type of model to use for bagging. Options include "linear", "logistic", "ridge", "lasso", "elastic_net", and "svm".}

\item{responseVariable}{Name of the response variable.}

\item{R}{Number of bootstrap samples.}

\item{type}{Type of model, either "default" for regression or "class" for classification.}

\item{lambda}{Regularization parameter for models that support it (e.g., Ridge, Lasso).}

\item{alpha}{Regularization parameter for models that support it (e.g., Lasso, Elastic Net).}

\item{ignoreWarnings}{Whether to ignore warnings during model fitting.}

\item{importance}{Whether to compute variable importance.}

\item{nfolds}{Number of folds for cross-validation.}

\item{kernel}{Kernel type for SVM models.}

\item{cost, }{degree, coef0, gamma, epsilon Hyperparameters for SVM models.}

\item{k}{Number of nearest neighbors for kNN models.}
}
\value{
A list containing predicted values, variable importance scores, and additional metrics.
}
\description{
Implements bagging (bootstrap aggregating) for machine learning models.
}
\examples{
# Binomial
x <- matrix(rnorm(10000), ncol = 10)
y <- factor(sample(0:1, 1000, replace = TRUE))
data = data.frame(x, y)

trainID <- sample(1:nrow(data), round(0.75 * nrow(data)))
trainData <- data[trainID, ]
testData <- data[-trainID, ]
model_bagged <- bagging(subset(trainData, select = -y), trainData$y, testData = testData, model_type = "svm", responseVariable = "y", R = 10, type = "class", importance = T)
model_bagged
model_bagged <- bagging(subset(trainData, select = -y), trainData$y, testData = testData, model_type = "logistic", responseVariable = "y", R = 10, type = "class", importance = T)
model_bagged


model_bagged <- bagging(subset(trainData, select = -y), trainData$y, testData = testData, model_type = "svm", responseVariable = "y", R = 10, type = "class", importance = T)
model_bagged
model_bagged <- bagging(subset(trainData, select = -y), trainData$y, testData = testData, model_type = "logistic", responseVariable = "y", R = 10, type = "class", importance = T)
model_bagged

# Multinomial

x <- matrix(rnorm(1500), ncol = 15)
y <- factor(sample(1:3, 100, replace = TRUE))

data = data.frame(x, y)

trainID <- sample(1:nrow(data), round(0.75 * nrow(data)))
trainData <- data[trainID, ]
testData <- data[-trainID, ]
model_bagged <- bagging(subset(trainData, select = -y), trainData$y, testData = testData, model_type = "svm", responseVariable = "y", R = 15, type = "class", importance = T)
model_bagged

# Regression
x <- matrix(rnorm(1000), ncol = 10)
y <- rnorm(100)
data = data.frame(x, y)

trainID <- sample(1:nrow(data), round(0.75 * nrow(data)))
trainData <- data[trainID, ]
testData <- data[-trainID, ]
model_bagged <- bagging(subset(trainData, select = -y), trainData$y, testData = testData, model_type = "linear", responseVariable = "y", R = 15, importance = F)
model_bagged

model = lm(y ~ ., data = trainData)
# preds = coef(model) %*% as.matrix(subset(testData, select = -y))
test_x = subset(testData, select = -y)
preds1 = predict(model, test_x)

rmse(preds1, testData$y)

}
