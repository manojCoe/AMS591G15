% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ensemble.R
\name{ensemble}
\alias{ensemble}
\title{Ensemble Model}
\usage{
ensemble(
  x,
  y,
  testData,
  responseVariable = NULL,
  models,
  alpha = NULL,
  lambda = NULL,
  bagging = FALSE,
  R = 10,
  importance = FALSE,
  type = "default",
  nfolds = 10,
  ignoreWarnings = T,
  kernel = "radial",
  cost = 1,
  degree = 3,
  coef0 = 0,
  gamma = NULL,
  epsilon = 0.1,
  k = 6
)
}
\arguments{
\item{x}{Predictor variables as a data frame or matrix.}

\item{y}{Response variable as a vector.}

\item{testData}{Test data for prediction.}

\item{responseVariable}{Name of the response variable in the testData.}

\item{models}{List of base models to be included in the ensemble.}

\item{alpha}{Regularization parameter for certain models.}

\item{lambda}{Regularization parameter for certain models.}

\item{bagging}{Logical indicating whether to use bagging for model combination.}

\item{R}{Number of bootstrap replicates if bagging is used.}

\item{importance}{Logical indicating whether to consider feature importance in model selection.}

\item{type}{Type of model, either "default" for regression or "class" for classification.}

\item{nfolds}{Number of folds for cross-validation.}

\item{ignoreWarnings}{Logical indicating whether to ignore warnings.}

\item{kernel}{Kernel type for SVM models.}

\item{cost}{Cost parameter for SVM models.}

\item{degree}{Degree of polynomial kernel for SVM models.}

\item{coef0}{Intercept in polynomial kernel for SVM models.}

\item{gamma}{Kernel coefficient for "radial", "polynomial", and "sigmoid" kernels for SVM models.}

\item{epsilon}{Tolerance parameter for SVM models.}

\item{k}{Number of important predictors to select.}
}
\value{
A list containing the ensemble predictions and, if applicable, evaluation metrics.
}
\description{
Fits an ensemble model using a combination of different base models.
}
\examples{
# ENSEMBLE
# Binomial
x <- matrix(rnorm(10000), ncol = 10)
y <- factor(sample(0:1, 1000, replace = TRUE))
data = data.frame(x, y)
trainID <- sample(1:nrow(data), round(0.75 * nrow(data)))
trainData <- data[trainID, ]
testData <- data[-trainID, ]
# model_bagged <- ensemble(subset(trainData, select = -y), trainData$y, testData = testData, models = c("logistic","svm","ridge","elastic_net"), responseVariable = "y", R = 15, type = "class", importance = F, lambda = 0.1)
model_bagged <- ensemble(subset(trainData, select = -y), trainData$y, testData = testData, models = c("logistic","svm","ridge","elastic_net"), responseVariable = "y", R = 15, type = "class", importance = T, k = 6)
model_bagged
# Multinomial Classification
x <- matrix(rnorm(1500), ncol = 15)
y <- factor(sample(1:3, 100, replace = TRUE))
data = data.frame(x, y)
trainID <- sample(1:nrow(data), round(0.75 * nrow(data)))
trainData <- data[trainID, ]
testData <- data[-trainID, ]
model_bagged <- ensemble(subset(trainData, select = -y), trainData$y, testData = testData, models = c("logistic","svm","ridge","elastic_net"), responseVariable = "y", R = 15, type = "class", importance = T, k = 6)
model_bagged
# Regression
x <- matrix(rnorm(1000), ncol = 10)
y <- rnorm(100)
data = data.frame(x, y)
trainID <- sample(1:nrow(data), round(0.75 * nrow(data)))
trainData <- data[trainID, ]
testData <- data[-trainID, ]
model_bagged <- ensemble(subset(trainData, select = -y), trainData$y, testData = testData, models = c("svm","ridge","elastic_net"), responseVariable = "y", R = 15, importance = F)
model_bagged
model = lm(y ~ ., data = trainData)
# preds = coef(model) \%*\% as.matrix(subset(testData, select = -y))
test_x = subset(testData, select = -y)
preds1 = predict(model, test_x)
rmse(preds1, testData$y)
}
